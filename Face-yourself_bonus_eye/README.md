# Face-yourself
## üçΩÔ∏è Syst√®me de Gestion de Cantine par Reconnaissance Faciale

<p align="center">
    <img src="/Documentation/logo-Face-yourself.png" alt="Logo Face Yourself" width="250"/>
</p>

Ce projet combine une interface de gestion des cr√©dits de cantine (via Tkinter et SQLite) avec un syst√®me d'authentification par reconnaissance faciale (via OpenCV et l'algorithme LBPH) pour automatiser le d√©bit des repas.

## ‚ú® Fonctionnalit√©s Principales

- **Gestion des √âl√®ves :** Ajout, consultation du cr√©dit et affichage de la liste compl√®te des √©l√®ves (Base de donn√©es SQLite).

- **Gestion des Cr√©dits :** Fonctionnalit√©s d'ajout de cr√©dit par un administrateur.

- **Capture d'Images :** Outil int√©gr√© pour collecter des √©chantillons de visages n√©cessaires √† l'entra√Ænement de l'IA.

- **Entra√Ænement du Mod√®le :** G√©n√©ration du fichier de mod√®le (trainer.yml) √† partir des images captur√©es.

- **D√©bit Automatis√© :** Utilisation de la cam√©ra pour identifier un √©l√®ve et d√©biter le co√ªt du repas de son compte si le cr√©dit est suffisant.

<p align="center">
  <a href="/Documentation/Maquette.pdf" target="_blank">
    <img src="/Documentation/page_principal.png" alt="Interface Graphique" width="250"/>
  </a>
</p>

## ‚öôÔ∏è Pr√©requis

Assurez-vous que les d√©pendances suivantes sont install√©es sur votre syst√®me :

    Python 3.x

    OpenCV (avec les contributions pour la reconnaissance faciale)

    NumPy

    Pillow (PIL)

Vous pouvez installer les biblioth√®ques requises via pip :
Bash

    pip install opencv-contrib-python numpy Pillow

## üöÄ Guide de D√©marrage Rapide

Pour que le syst√®me fonctionne, il est crucial de suivre ces √©tapes dans l'ordre pour configurer la base de donn√©es et entra√Æner le mod√®le d'IA.

### √âtape 1 : Lancement de l'Application

Lancez le script Python principal :
Bash

    python Cantine_reconnaissance.py

### √âtape 2 : Enregistrement des √âl√®ves

Utilisez la section **"Administration & Entra√Ænement"** dans l'interface Tkinter :

Cliquez sur **"1. Ajouter un √âl√®ve".**

Entrez le nom et le pr√©nom. **L'ID de l'√©l√®ve sera affich√© dans la bo√Æte de dialogue de succ√®s.** Cet ID est l'identifiant unique utilis√© par la DB et le mod√®le d'IA.

### √âtape 3 : Capture des Images du Visage

L'IA a besoin d'images pour apprendre. Utilisez l'ID obtenu √† l'√©tape pr√©c√©dente.

Cliquez sur **"4. Capturer Images √âl√®ve".**

Entrez l'ID de l'√©l√®ve cr√©√© √† l'√©tape 2.

La cam√©ra s'ouvrira. Positionnez l'√©l√®ve devant la cam√©ra et faites-lui effectuer quelques l√©gers mouvements de t√™te et expressions.

Le syst√®me capturera 30 images et les enregistrera dans le dossier dataset/ID_√âL√àVE/.

### √âtape 4 : Entra√Ænement du Mod√®le d'IA

Une fois que vous avez captur√© les images pour tous les √©l√®ves √† reconna√Ætre, vous devez entra√Æner l'IA :

Cliquez sur **"5. Entra√Æner le Mod√®le (Cr√©er trainer.yml)".**

Le processus de calcul commence. Une fois termin√©, le fichier trainer.yml sera cr√©√© ou mis √† jour dans le r√©pertoire racine du projet. Ce fichier est le cerveau de la reconnaissance faciale.

### √âtape 5 : Gestion des Cr√©dits

Avant le premier d√©bit, assurez-vous que les √©l√®ves ont des fonds :

Cliquez sur **"2. Ajouter du Cr√©dit".**

Entrez l'ID de l'√©l√®ve et le montant √† cr√©diter.

## üöÄ Utilisation du Syst√®me de D√©bit

Cette fonctionnalit√© est le c≈ìur du projet, utilis√©e pour le service de cantine.

Cliquez sur **"SCANNER LE VISAGE & D√âBITER"**.

La cam√©ra s'ouvrira apr√®s une br√®ve phase de stabilisation (quelques secondes) pour √©viter les plantages.

Positionnez l'√©l√®ve devant la cam√©ra.

Une fois l'√©l√®ve identifi√© (bo√Æte verte), le programme valide la transaction.

Le co√ªt du repas (5.00 ‚Ç¨ par d√©faut) sera d√©bit√© du compte, et une bo√Æte de dialogue Tkinter confirmera la transaction et affichera le nouveau solde.

Pour annuler et fermer la cam√©ra sans d√©biter, appuyez sur √âchap (Esc).

## üìö Structure du Projet

| Fichier/Dossier  | R√¥le         | 
| :---------------|:---------------:|
| ``` Cantine_reconnaissance.py ``` | Contient le code principal, l'interface Tkinter et la logique d'ex√©cution.|
| ``` eleves.db ``` | Base de donn√©es SQLite contenant les informations des √©l√®ves (ID, nom, pr√©nom, cr√©dit).|
| ``` dataset/ ```| Dossier de travail pour stocker les images captur√©es (class√©es par sous-dossiers ID).|
| ``` trainer.yml ```| Mod√®le de reconnaissance faciale LBPH g√©n√©r√© apr√®s l'entra√Ænement.|


## üõ†Ô∏è D√©pannage et Maintenance


| Probl√®me  | Cause         | Solution        | 
| :---------------|:---------------:|:---------------:|
| **√âcran de cam√©ra noir** | Mauvais index de cam√©ra ou cam√©ra d√©j√† utilis√©e.| Modifiez l'index de cv2.VideoCapture(0) √† 1 ou 2. Fermez les autres applications de cam√©ra.| 
| **D√©tection trop rapide/plantage** | Conflit entre OpenCV et Tkinter lors de la fermeture. | Le script int√®gre un d√©lai de stabilisation (10 frames) qui devrait r√©soudre ce probl√®me. | 
| **√âl√®ve non reconnu (Inconnu)**| Confiance trop faible ou manque de donn√©es. | Augmentez la luminosit√©, capturez plus d'images pour cet ID, puis relancez l'entra√Ænement (√âtape 4).| 
| ``` trainer.yml ``` **manquant**| Le mod√®le n'a jamais √©t√© entra√Æn√©. | Suivez l'√âtape 4 : Entra√Ænement du Mod√®le d'IA.| 

___

 ## üîç Explication: Comment j'ai r√©alis√© ce projet ?

Je me suis renseign√© sur comment d√©tecter un visage, et j'ai trouv√© ce lien qui m'a √©norm√©ment aid√© : 
[Face Detection Python (opencv)](https://www.datacamp.com/fr/tutorial/face-detection-python-opencv)

J'ai pu faire en sorte qu'il d√©tecte les visages sans savoir qui c'est pour le moment. Cette premi√®re √©tape s'est bas√©e sur l'utilisation de l'algorithme **Haar Cascade**, charg√© via : ```cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml") ```

## üí° Le D√©fi de la Reconnaissance Faciale

C'est donc l√† qu'est venue la deuxi√®me √©tape : trouver comment passer de la **d√©tection** (savoir o√π est le visage) √† la **reconnaissance** (savoir √† qui appartient ce visage). J'ai d√©fini les objectifs suivants :

1. **Enregistrer des photos :** Collecter des images de r√©f√©rence pour chaque personne.

2. **Cr√©er une empreinte du visage (ou embedding) :** Extraire des caract√©ristiques num√©riques uniques du visage pour l'identification.

3. **Reconna√Ætre gr√¢ce √† la cam√©ra :** Comparer l'empreinte en direct avec celles enregistr√©es.

1. **La Cr√©ation de l'Empreinte (Embedding)**

Pour la cr√©ation de l'empreinte, je me suis rendu sur la documentation officielle de Python et d'OpenCV pour esp√©rer trouver mon bonheur. Malheureusement, ce ne fut pas le cas, du moins pas compl√®tement. J'ai trouv√© quelques bouts de code int√©ressants mais pas suffisants (la documentation est vraiment immense, avec des formules math√©matiques et des termes que je ne connaissais m√™me pas).

J'ai compris qu'il fallait utiliser un mod√®le de machine learning entra√Æn√© √† convertir une image de visage en un **vecteur de nombres** (l'empreinte). C'est ce vecteur, et non l'image elle-m√™me, qui est stock√©.

J'ai d√ª demander √† l'IA comment utiliser ces bouts de code, notamment pour la partie cruciale de la reconnaissance elle-m√™me. Pour cela, j'ai finalement opt√© pour l'algorithme Local Binary Patterns Histograms (LBPH), un algorithme d'OpenCV bien adapt√© pour cette t√¢che et relativement simple √† mettre en ≈ìuvre par rapport aux solutions bas√©es sur le Deep Learning.

L'entra√Ænement du mod√®le LBPH (m√©thode ```cv2.face.LBPHFaceRecognizer_create()```) se r√©sume √† :

- **R√©cup√©rer** toutes les images de r√©f√©rence.

- **Convertir** chaque visage en son empreinte (ensemble de patterns binaires).

- **Stocker** ces empreintes avec l'ID de la personne correspondante.

2. Reconnaissance en Temps R√©el

Une fois l'√©tape d'entra√Ænement termin√©e, la reconnaissance en temps r√©el est devenue plus simple. √Ä chaque nouvelle image captur√©e par la cam√©ra :

1. Le **Haar Cascade** d√©tecte un visage (trouve les coordonn√©es du rectangle).

2. Le visage d√©tect√© est transmis au mod√®le **LBPH**.

3. Le mod√®le compare l'empreinte du visage actuel avec toutes celles enregistr√©es et renvoie l'ID de la personne la plus proche, ainsi qu'un **niveau de confiance** (plus il est bas, plus la correspondance est bonne).

C'est cette valeur de confiance (``` threshold = 75 ```)  qui permet de d√©cider si l'on affiche le nom de la personne ou le libell√© "Inconnu".